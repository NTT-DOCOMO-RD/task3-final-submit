{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from cleanlab.filter import find_label_issues\n",
    "from tqdm import tqdm\n",
    "import demoji\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers import evaluation\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 2022\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "num_epochs = 1\n",
    "num_labels = 2\n",
    "max_length = 512\n",
    "\n",
    "# target language of model training (multi, us, es)\n",
    "# For JP, please use train_jp.ipynb\n",
    "target_lang = 'es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_task1 = './data/task1/'\n",
    "data_path_task2 = './data/task2/'\n",
    "\n",
    "train_df_task1 = pd.read_csv(data_path_task1+'train-v0.3.csv.zip')\n",
    "train_df_task2 = pd.read_csv(data_path_task2+'train-v0.3.csv.zip')\n",
    "product_df = pd.read_csv(data_path_task2+'product_catalogue-v0.3.csv.zip')\n",
    "\n",
    "train_df = pd.concat([train_df_task1[['query','query_locale','product_id','esci_label']],\n",
    "           train_df_task2[['query','query_locale','product_id','esci_label']]]).drop_duplicates()\n",
    "\n",
    "train_df['query_id'] = train_df[\"query\"].factorize()[0] + 0\n",
    "\n",
    "train_df = train_df.merge(product_df,left_on = ['product_id','query_locale'],right_on=['product_id','product_locale'], how= 'left')\n",
    "print(train_df.shape)\n",
    "\n",
    "train_df['label'] = train_df['esci_label'].map({'exact':0, 'substitute':1, 'complement':0, 'irrelevant':0})\n",
    "\n",
    "if target_lang=='multi':\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "if target_lang=='us':\n",
    "    train_df = train_df[train_df.query_locale=='us'].reset_index(drop=True)\n",
    "if target_lang=='es':\n",
    "    train_df = train_df[train_df.query_locale=='es'].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_normalize(s):\n",
    "    norm_text = re.sub(r'(http|https)://([-\\w]+\\.)+[-\\w]+(/[-\\w./?%&=]*)?', \"\", s)\n",
    "    norm_text = unicodedata.normalize(\"NFKC\", norm_text)\n",
    "    norm_text = demoji.replace(string=norm_text, repl=\"\")\n",
    "    \n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data type and normalize text\n",
    "train_df['query'] = train_df['query'].astype(str)\n",
    "train_df['query'] = train_df['query'].map(str_normalize)\n",
    "train_df['product_title'] = train_df['product_title'].astype(str)\n",
    "train_df['product_title'] = train_df['product_title'].map(str_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into train and valid (if needed, local test set is also created)\n",
    "list_query_id = train_df[\"query_id\"].unique()\n",
    "\n",
    "# list_query_id_train, list_query_id_test = train_test_split(list_query_id, test_size=0.2, random_state=SEED)\n",
    "list_query_id_train, list_query_id_dev = train_test_split(list_query_id, test_size=0.1, random_state=SEED)\n",
    "\n",
    "df_train = train_df[train_df[\"query_id\"].isin(list_query_id_train)]\n",
    "df_dev = train_df[train_df[\"query_id\"].isin(list_query_id_dev)]\n",
    "# df_test = train_df[train_df[\"query_id\"].isin(list_query_id_test)]\n",
    "\n",
    "print('train size',df_train.shape)\n",
    "print('valid size',df_dev.shape)\n",
    "# print('test size',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sample balance for two-phase learning\n",
    "BALANCED_SAMPLE_NUM = int(train_df['label'].value_counts()[1] + train_df['label'].value_counts()[1]*0.1)\n",
    "print(BALANCED_SAMPLE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train_sampled_exact = df_train[df_train.label==0].sample(BALANCED_SAMPLE_NUM,random_state=SEED)\n",
    "df_train_sampled_no_exact = df_train[df_train.label!=0]\n",
    "\n",
    "tgt_idx = list(df_train_sampled_exact.index.tolist()) + list(df_train_sampled_no_exact.index.tolist())\n",
    "df_train_balanced = df_train.iloc[tgt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "for (_, row) in df_train.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_balanced = []\n",
    "for (_, row) in df_train_balanced.iterrows():\n",
    "    train_samples_balanced.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader_balanced = DataLoader(train_samples_balanced, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples = []\n",
    "for (_, row) in df_dev.iterrows():\n",
    "    dev_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_samples = []\n",
    "# for (_, row) in df_test.iterrows():\n",
    "#     test_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_lang=='multi':\n",
    "    model_save_path = 'model/task3_model_multi'\n",
    "    model_name = 'microsoft/mdeberta-v3-base'\n",
    "if target_lang=='us':\n",
    "    model_save_path = 'model/task3_model_us'\n",
    "    model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "if target_lang=='es':\n",
    "    model_save_path = 'model/task3_model_es'\n",
    "    model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "    \n",
    "model = CrossEncoder(model_name, num_labels=num_labels)\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='train-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10% of train data for warm-up\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "# Train the model with balanced sample\n",
    "model.fit(train_dataloader=train_dataloader_balanced,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the original sample ratio\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for test data (If needed)\n",
    "# evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(test_samples, name='train-test')\n",
    "# evaluator(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
