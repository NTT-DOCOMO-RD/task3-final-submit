{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from cleanlab.filter import find_label_issues\n",
    "from tqdm import tqdm\n",
    "import demoji\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers import evaluation\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 2022\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "num_epochs = 1\n",
    "num_labels = 2\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_task1 = './data/task1/'\n",
    "data_path_task2 = './data/task2/'\n",
    "\n",
    "train_df_task1 = pd.read_csv(data_path_task1+'train-v0.3.csv.zip')\n",
    "train_df_task2 = pd.read_csv(data_path_task2+'train-v0.3.csv.zip')\n",
    "product_df = pd.read_csv(data_path_task2+'product_catalogue-v0.3.csv.zip')\n",
    "\n",
    "train_df = pd.concat([train_df_task1[['query','query_locale','product_id','esci_label']],\n",
    "           train_df_task2[['query','query_locale','product_id','esci_label']]]).drop_duplicates()\n",
    "\n",
    "train_df['query_id'] = train_df[\"query\"].factorize()[0] + 0\n",
    "\n",
    "train_df = train_df.merge(product_df,left_on = ['product_id','query_locale'],right_on=['product_id','product_locale'], how= 'left')\n",
    "print(train_df.shape)\n",
    "\n",
    "train_df['label'] = train_df['esci_label'].map({'exact':0, 'substitute':1, 'complement':0, 'irrelevant':0})\n",
    "train_df = train_df[train_df.query_locale=='jp'].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_normalize(s):\n",
    "    norm_text = re.sub(r'(http|https)://([-\\w]+\\.)+[-\\w]+(/[-\\w./?%&=]*)?', \"\", s)\n",
    "    norm_text = unicodedata.normalize(\"NFKC\", norm_text)\n",
    "    norm_text = demoji.replace(string=norm_text, repl=\"\")\n",
    "    \n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data type and normalize text\n",
    "train_df['query'] = train_df['query'].astype(str)\n",
    "train_df['query'] = train_df['query'].map(str_normalize)\n",
    "train_df['product_title'] = train_df['product_title'].astype(str)\n",
    "train_df['product_title'] = train_df['product_title'].map(str_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into train and valid (if needed, local test set is also created)\n",
    "list_query_id = train_df[\"query_id\"].unique()\n",
    "\n",
    "# list_query_id_train, list_query_id_test = train_test_split(list_query_id, test_size=0.2, random_state=SEED)\n",
    "list_query_id_train, list_query_id_dev = train_test_split(list_query_id, test_size=0.1, random_state=SEED)\n",
    "# 2-Fold Cross-validation for label cleaning (CleanLab)\n",
    "# Note: We tried CleanLab for all langulages, but it was only effective for Japanese\n",
    "list_query_id_train1, list_query_id_train2 = train_test_split(list_query_id_train, test_size=0.5, random_state=SEED)\n",
    "\n",
    "df_train1 = train_df[train_df[\"query_id\"].isin(list_query_id_train1)]\n",
    "df_train2 = train_df[train_df[\"query_id\"].isin(list_query_id_train2)]\n",
    "df_dev = train_df[train_df[\"query_id\"].isin(list_query_id_dev)]\n",
    "# df_test = train_df[train_df[\"query_id\"].isin(list_query_id_test)]\n",
    "\n",
    "print('train CV1 size',df_train1.shape)\n",
    "print('train CV2 size',df_train2.shape)\n",
    "print('valid size',df_dev.shape)\n",
    "# print('test size',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples1 = []\n",
    "for (_, row) in df_train1.iterrows():\n",
    "    train_samples1.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader1 = DataLoader(train_samples1, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "\n",
    "train_samples2 = []\n",
    "for (_, row) in df_train2.iterrows():\n",
    "    train_samples2.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader2 = DataLoader(train_samples2, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples = []\n",
    "for (_, row) in df_dev.iterrows():\n",
    "    dev_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_samples = []\n",
    "# for (_, row) in df_test.iterrows():\n",
    "#     test_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path1 = 'models/model_jp_CleanLab_CV1'\n",
    "model_save_path2 = 'models/model_jp_CleanLab_CV2'\n",
    "\n",
    "model = CrossEncoder('cl-tohoku/bert-base-japanese-v2', num_labels=num_labels)\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='train-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader1) * num_epochs * 0.1)\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader1,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferece for train data CV2 using the model trained by CV1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_save_path1).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_save_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_query = df_train2['query'].to_list()\n",
    "features_product = df_train2['product_title'].to_list()\n",
    "\n",
    "n_examples = len(features_query)\n",
    "scores = np.empty((0, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, n_examples, BATCH_SIZE)):\n",
    "        j = min(i + BATCH_SIZE, n_examples)\n",
    "        features_query_ = features_query[i:j]\n",
    "        features_product_ = features_product[i:j]\n",
    "        features = tokenizer(features_query_, features_product_,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        scores = np.vstack((scores, np.squeeze(model(**features).logits.cpu().detach().numpy())))\n",
    "        i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = softmax(scores, axis=1)\n",
    "\n",
    "ranked_label_issues_train2 = find_label_issues(\n",
    "    df_train2['label'],\n",
    "    pred_probs,\n",
    "    return_indices_ranked_by=\"self_confidence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swith CV\n",
    "model = CrossEncoder('cl-tohoku/bert-base-japanese-v2', num_labels=num_labels)\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader2) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader2,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_save_path2).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_save_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_query = df_train1['query'].to_list()\n",
    "features_product = df_train1['product_title'].to_list()\n",
    "\n",
    "n_examples = len(features_query)\n",
    "scores = np.empty((0, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, n_examples, BATCH_SIZE)):\n",
    "        j = min(i + BATCH_SIZE, n_examples)\n",
    "        features_query_ = features_query[i:j]\n",
    "        features_product_ = features_product[i:j]\n",
    "        features = tokenizer(features_query_, features_product_,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        scores = np.vstack((scores, np.squeeze(model(**features).logits.cpu().detach().numpy())))\n",
    "        i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = softmax(scores, axis=1)\n",
    "\n",
    "ranked_label_issues_train1 = find_label_issues(\n",
    "    df_train1['label'],\n",
    "    pred_probs,\n",
    "    return_indices_ranked_by=\"self_confidence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model without noisy data\n",
    "df_train = pd.concat([df_train1, df_train2])\n",
    "label_issues_idx = ranked_label_issues_train1.tolist() + ranked_label_issues_train2.tolist()\n",
    "\n",
    "train_samples = []\n",
    "for (_, row) in df_train.iloc[~df_train.index.isin(label_issues_idx)].iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sample balance for two-phase learning\n",
    "BALANCED_SAMPLE_NUM = int(df_train['label'].value_counts()[1] + df_train['label'].value_counts()[1]*0.1)\n",
    "print(BALANCED_SAMPLE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train_sampled_exact = df_train[df_train.label==0].sample(BALANCED_SAMPLE_NUM,random_state=SEED)\n",
    "df_train_sampled_no_exact = df_train[df_train.label!=0]\n",
    "\n",
    "tgt_idx = list(df_train_sampled_exact.index.tolist()) + list(df_train_sampled_no_exact.index.tolist())\n",
    "df_train_balanced = df_train.iloc[tgt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_balanced = []\n",
    "for (_, row) in df_train_balanced.iterrows():\n",
    "    train_samples_balanced.append(InputExample(texts=[row['query'], row['product_title']], label=int(row['label'])))\n",
    "    \n",
    "train_dataloader_balanced = DataLoader(train_samples_balanced, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder('cl-tohoku/bert-base-japanese-v2', num_labels=num_labels)\n",
    "\n",
    "model_save_path = 'models/task3_model_jp'\n",
    "warmup_steps = math.ceil(len(train_dataloader_balanced) * num_epochs * 0.1)\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader_balanced,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=500,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for test data (If needed)\n",
    "# evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(test_samples, name='train-test')\n",
    "# evaluator(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
